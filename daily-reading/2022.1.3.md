## \[2021 NAACL\] Towards Interpreting and Mitigating Shortcut Learning

why ML fails?

### Observation
For long-tail disbutrition in NLU tasks, model focus on shortcut features of head classes. This can happen at very early stage of training.

### Solution
Use knowledge distillation (teacher + student model) and smooth softmax to mitigate over confident predictions.

How to discover shortcuts?
- data statistics: local mutual information (LMI)
- model behavior: integrated gradients (calculat grad of prediction w.r.t. input features). get feature importance vector.

Experiments show that model heavily rely on LMI features by analyzing its integrated gradients.

**notes**: can these model interpretation methods truely reflect how model works?

## \[2021 ICCV\] Beyond Question-Based Biases: Assessing Multimodal Shortcut Learning in Visual Question Answering

### Idea
Propose to measure multimodal shortcuts, not only the question-based shortcuts, as shortcuts can also come from image modality.

### Method
Assess models by counter examples that fail simple rules.

**notes**: why to say the examples in the paper show spurious correlation instead of causal relation? such appearance of elements seem to be sufficient to make the prediction.