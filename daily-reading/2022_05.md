## \[2022 arxiv\] Causality Inspired Representation Learning for Domain Generalization
### Motivation
Learning causal features to solve the domain generalization problem.
### Key Idea
The causal (S) and non-causal (U) factors are not saperated in most dataset. Thus we learn features to **mimic** the property of causal features.

The principles (properties) of causal features:
- Common Cause Principle. This is the causal graph S -> X <- U and S->Y.
  > All mutual information between U and X are passed by S. That is, given S, X and U are no longer dependent.
- Indenpend Causal Mechanisms Principle. The causal features are mutually independent.
  > This is used by many works, like Barlo Twins.

### Methodology
- Causal intervention. do(U) and force the learned features invariant. Treat Fourier transformation's phase as S and amplitude as U.
- Causal Factorization Module. Let the correlation matrix of learned features to be diagonal.
- Adversarial mask. To make each dimension informative.

### Comments
The techniques are familar and a new story interpretation.

## \[2022 arxiv\] DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings
DiffCSE

## \[2021 EMNLP\] SimCSE: Simple Contrastive Learning of Sentence Embeddings
SimCSE

## \[2022 ICLR\] A Fine-Grained Analysis on Distribution Shift
### Overview
Analysis OOD types and evaluate various models

### OOD types
input:x, label:$y^l$, attributes: $y^1, y^2, ..., y^K$

distribution shifts:
- **SC**: spurious correlation. $p(y^a|y^b)$ changes under train and test.
- **LDD**: low-data drift: $p(y^a)$ changes under train and test
- **UDD**: unseen data drift. some values of $y^a$ are not seen in training set.

### Comments
There is another unseen scenario, which is caused by the sparsity of input sapce.

## \[2020 NIPS\] Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases


## \[2021 Arxiv\] A Survey on Understanding, Visualizations, and Explanation of Deep Neural Networks
### Structural Analysis
For CNN, the meaning of layer weights is depend on the layer input. As the first layer's input is the pixel space, then the first layer's weights (filters) can be visualized in the pixel space.

